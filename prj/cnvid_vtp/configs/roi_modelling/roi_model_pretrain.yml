task_attributes:
  roi_task:
    dataset_size_proportional_sampling: true
    dataset_attributes:
      roi_dataset:
        pretraining: True # indicate dataset is built for pretraining
        data_root_dir: ../tests/data/roi_data

        annotations:
          train: dev.jsonl
          val: dev.jsonl
          test: dev.jsonl

        use_images: True
        images:
          train: imgs
          val: imgs
          test: imgs

        use_ocrs: True
        ocrs:
          train: ocrs
          val: ocrs
          test: ocrs

        use_features: True
        fast_read: False
        features:
          train: rois
          val: rois
          test: rois

        processors: &test_processors
          ocr_processor: # tokenizer for ocr
            type: masked_layoutlm_tokenizer
            params:
              max_seq_length: 50
              # 图像输出特征数目+最大文本长度+2
              # 总长度如果取大了，可能会有OOM
              mask_probability: 0.15
              trim_start_token: True # not output start token id
              tokenizer_config:
                type: bert-base-chinese
                params:
                  do_lower_case: true
              preprocessor:
                type: simple_word
                params: {}

          caption_processor: &caption_processor
            type: masked_bert_tokenizer
            params:
              max_seq_length: 10 # max_length for each text field
              mask_probability: 0.15
              trim_start_token: True # not output start token id, because text info is appended to image info in later encoding stage
              tokenizer_config:
                type: bert-base-chinese
                params:
                  model_type: bert
                  do_lower_case: true
              preprocessor:
                type: simple_sentence
                params: {}

          region_processor:
            type: region_processor
            params:
              max_features: 10
              feature_dim: 2048 # feature dim for each image region
              region_kl_fc_dim: &region_kl_fc_dim 13  # num_class for masked region classification loss(kl_loss)
              required_feature_info_key: # required keys for feature-info numpy file
                - max_features
                - cls_prob
                - bbox
                - image_height
                - image_width
              mask_region_prob: 0.15
          

          train_image_processor:
            type: torchvision_transforms
            params:
              transforms:
                - type: Resize
                  params:
                    size: [256, 256]
                - type: RandomCrop
                  params:
                    size: [224, 224]
                - RandomHorizontalFlip
                - ToTensor
                - type: Normalize
                  params:
                    mean: [0.485, 0.456, 0.406]
                    std: [0.229, 0.224, 0.225]

          test_image_processor: &test_image_processor
            type: torchvision_transforms
            params:
              transforms:
                - type: Resize
                  params:
                    size: [224, 224]
                - ToTensor
                - type: Normalize
                  params:
                    mean: [0.485, 0.456, 0.406]
                    std: [0.229, 0.224, 0.225]

model_attributes:
  roi_model:
    training_head_type: pretraining
    pretrained: true

    bert_model_name: bert-base-chinese
    #    training_head_type: classification
    #    classifier_type: mlp_classifier
    #    num_labels: 2
    region_kl_fc_dim: *region_kl_fc_dim # num_class for region kl_loss

    inter_token_id: 102 # token id for separating image tokens, default as [SEP](102)
    img_token_interval: 1 # take effect when having multiple images as input

    img_hidden_sz: 2048
    num_image_embeds: 1 # if there are multiple objects can be detected,
    # and each have their own features, can set this to corresponding number
    hidden_size: 768
    hidden_act: gelu
    vocab_size: 21128
    layer_norm_eps: 1e-12
    initializer_range: 0.02

    special_visual_initialize: true
    embedding_strategy: plain
    bypass_transformer: false
    output_attentions: false
    output_hidden_states: false
    random_initialize: false
    freeze_base: false
    finetune_lr_multiplier: 0.1 # TODO: fix me
    dropout: 0.1

    # Default points to BERT pooler strategy which is to take
    # representation of CLS token after passing it through a dense layer
    pooler_strategy: default

    image_encoder:
      # TODO: refer to pixelBERT for pretraining
      type: BatchImageEncoder
      params:
        encoder_type: resnet50
        pretrained: true
        pool_type: avg
        # 图像编码器的输出特征数目
        # 这个数目+最多文本长度+2 <= 512
        # 512 是BERT模型的输入长度
        num_output_features: 8

        
    layoutlm_embedding_config:
      vocab_size: 21128
      hidden_size: 768
      padding_idx: 0
      max_position_embeddings: 256 # ocr max length
      max_2d_position_embeddings: 1024
      type_vocab_size: 2
      hidden_dropout_prob: 0.1
      layer_norm_eps: 1e-6

    region_embedding_config:
      visual_feature_size: 2048



optimizer_attributes:
  type: AdamW
  params:
    lr: 1e-4
    weight_decay: 0.01


training_parameters:
    clip_norm_mode: all
    clip_gradients: true
    max_grad_l2_norm: 1.0
    lr_scheduler: true
    lr_ratio: 0.1
    lr_steps:
    - 200000
    - 500000
    use_warmup: false
    warmup_factor: 0.1
    warmup_iterations: 2000
    max_iterations: 20
    max_epochs: 20
    patience: 1000000
    batch_size: 2
    num_workers: 0
    task_size_proportional_sampling: true
    monitored_metric: total_loss
    metric_minimize: true
    report_format: csv
    snapshot_interval: 10
    log_interval: 2
    max_ckpt_num: 10

